{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Foundational Gradients ---\n",
      "∂L/∂S = p*t*(0.9**(1/p) - 1)*(y*(((s + t*(0.9**(1/p) - 1))/s)**p - 1) - ((s + t*(0.9**(1/p) - 1))/s)**p*(y - 1))/(s*(s + t*(0.9**(1/p) - 1))*(((s + t*(0.9**(1/p) - 1))/s)**p - 1))\n",
      "∂L/∂p = (0.105360515657826*0.9**(1/p)*t + p*(s + t*(0.9**(1/p) - 1))*log((s + t*(0.9**(1/p) - 1))/s))*(-y*(((s + t*(0.9**(1/p) - 1))/s)**p - 1) + ((s + t*(0.9**(1/p) - 1))/s)**p*(y - 1))/(p*(s + t*(0.9**(1/p) - 1))*(((s + t*(0.9**(1/p) - 1))/s)**p - 1))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, log, diff, exp, Pow\n",
    "\n",
    "# Define symbols for Loss and Retrievability\n",
    "y, s, t, p = symbols(\"y s t p\")\n",
    "\n",
    "# Retrievability (R) and Loss (L)\n",
    "factor = Pow(0.9, 1 / p) - 1\n",
    "R = (1 + factor * t / s) ** p\n",
    "L = -(y * log(R) + (1 - y) * log(1 - R))\n",
    "\n",
    "# ∂L/∂s (Gradient of Loss w.r.t. Stability)\n",
    "dL_ds = diff(L, s).simplify()\n",
    "# ∂L/∂p (Gradient of Loss w.r.t. decay parameter)\n",
    "dL_dp = diff(L, p).simplify()\n",
    "\n",
    "print(\"--- Foundational Gradients ---\")\n",
    "print(f\"∂L/∂S = {dL_ds}\")\n",
    "print(f\"∂L/∂p = {dL_dp}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradients for stability_after_success ---\n",
      "∂S_new/∂w8 = s_last**(1 - w9)*w15*w16*(d_last - 11)*(exp(w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)) - 1)*exp(-w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1) + w8)\n",
      "∂S_new/∂w9 = s_last**(1 - w9)*w15*w16*(1 - exp(w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)))*(d_last - 11)*exp(-w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1) + w8)*log(s_last)\n",
      "∂S_new/∂w10 = s_last**(1 - w9)*w15*w16*(d_last - 11)*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)*exp(-w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1) + w8)\n",
      "∂S_new/∂w15 = s_last**(1 - w9)*w16*(d_last - 11)*(exp(w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)) - 1)*exp(-w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1) + w8)\n",
      "∂S_new/∂w16 = s_last**(1 - w9)*w15*(d_last - 11)*(exp(w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)) - 1)*exp(-w10*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1) + w8)\n",
      "∂S_new/∂D_last = s_last**(1 - w9)*w15*w16*exp(w8) - s_last**(1 - w9)*w15*w16*exp(-w10*(0.9**(1/p)*t/s_last + 1 - t/s_last)**p + w10 + w8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, exp, log, diff, Pow\n",
    "\n",
    "# Define symbols\n",
    "s_last, d_last, t, p, rating = symbols(\"s_last d_last t p rating\")\n",
    "w8, w9, w10, w15, w16 = symbols(\"w8 w9 w10 w15 w16\")\n",
    "\n",
    "# Retrievability (r) at the last step\n",
    "factor = Pow(0.9, 1 / p) - 1\n",
    "r = (1 + factor * t / s_last) ** p\n",
    "\n",
    "# S_new for success case\n",
    "s_new_success = s_last * (\n",
    "    1 + exp(w8) * (11 - d_last) * s_last ** (-w9) * (exp((1 - r) * w10) - 1) * w15 * w16\n",
    ")\n",
    "\n",
    "# Derivatives w.r.t weights\n",
    "ds_dw8 = diff(s_new_success, w8).simplify()\n",
    "ds_dw9 = diff(s_new_success, w9).simplify()\n",
    "ds_dw10 = diff(s_new_success, w10).simplify()\n",
    "ds_dw15 = diff(s_new_success, w15).simplify()\n",
    "ds_dw16 = diff(s_new_success, w16).simplify()\n",
    "\n",
    "# Derivative w.r.t last difficulty (for chain rule)\n",
    "ds_d_last = diff(s_new_success, d_last).simplify()\n",
    "\n",
    "print(\"--- Gradients for stability_after_success ---\")\n",
    "print(f\"∂S_new/∂w8 = {ds_dw8}\")\n",
    "print(f\"∂S_new/∂w9 = {ds_dw9}\")\n",
    "print(f\"∂S_new/∂w10 = {ds_dw10}\")\n",
    "print(f\"∂S_new/∂w15 = {ds_dw15}\")\n",
    "print(f\"∂S_new/∂w16 = {ds_dw16}\")\n",
    "print(f\"∂S_new/∂D_last = {ds_d_last}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradients for stability_after_failure ---\n",
      "--- Branch 1: Main Formula ---\n",
      "∂S_main/∂w11 = ((s_last + 1)**w13 - 1)*exp(-w14*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1))/d_last**w12\n",
      "∂S_main/∂w12 = -w11*((s_last + 1)**w13 - 1)*exp(-w14*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1))*log(d_last)/d_last**w12\n",
      "∂S_main/∂w13 = w11*(s_last + 1)**w13*exp(-w14*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1))*log(s_last + 1)/d_last**w12\n",
      "∂S_main/∂w14 = -w11*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1)*((s_last + 1)**w13 - 1)*exp(-w14*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1))/d_last**w12\n",
      "∂S_main/∂D_last = -d_last**(-w12 - 1)*w11*w12*((s_last + 1)**w13 - 1)*exp(-w14*(((s_last + t*(0.9**(1/p) - 1))/s_last)**p - 1))\n",
      "\n",
      "--- Branch 2: Minimum Penalty ---\n",
      "∂S_min/∂w17 = -s_last*w18*exp(-w17*w18)\n",
      "∂S_min/∂w18 = -s_last*w17*exp(-w17*w18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, exp, log, diff, Pow\n",
    "\n",
    "# Define symbols\n",
    "s_last, d_last, t, p = symbols(\"s_last d_last t p\")\n",
    "w11, w12, w13, w14, w17, w18 = symbols(\"w11 w12 w13 w14 w17 w18\")\n",
    "\n",
    "# Retrievability (r) at the last step\n",
    "factor = Pow(0.9, 1 / p) - 1\n",
    "r = (1 + factor * t / s_last) ** p\n",
    "\n",
    "# Branch 1: The main failure formula\n",
    "s_main = w11 * d_last ** (-w12) * ((s_last + 1) ** w13 - 1) * exp((1 - r) * w14)\n",
    "ds_main_dw11 = diff(s_main, w11).simplify()\n",
    "ds_main_dw12 = diff(s_main, w12).simplify()\n",
    "ds_main_dw13 = diff(s_main, w13).simplify()\n",
    "ds_main_dw14 = diff(s_main, w14).simplify()\n",
    "ds_main_d_last = diff(s_main, d_last).simplify()\n",
    "\n",
    "# Branch 2: The minimum stability penalty\n",
    "s_min = s_last / exp(w17 * w18)\n",
    "ds_min_dw17 = diff(s_min, w17).simplify()\n",
    "ds_min_dw18 = diff(s_min, w18).simplify()\n",
    "\n",
    "print(\"--- Gradients for stability_after_failure ---\")\n",
    "print(\"--- Branch 1: Main Formula ---\")\n",
    "print(f\"∂S_main/∂w11 = {ds_main_dw11}\")\n",
    "print(f\"∂S_main/∂w12 = {ds_main_dw12}\")\n",
    "print(f\"∂S_main/∂w13 = {ds_main_dw13}\")\n",
    "print(f\"∂S_main/∂w14 = {ds_main_dw14}\")\n",
    "print(f\"∂S_main/∂D_last = {ds_main_d_last}\")\n",
    "print(\"\\n--- Branch 2: Minimum Penalty ---\")\n",
    "print(f\"∂S_min/∂w17 = {ds_min_dw17}\")\n",
    "print(f\"∂S_min/∂w18 = {ds_min_dw18}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradients for stability_short_term ---\n",
      "∂S_short/∂w17 = s_last**(1 - w19)*(rating + w18 - 3)*exp(w17*(rating + w18 - 3))\n",
      "∂S_short/∂w18 = s_last**(1 - w19)*w17*exp(w17*(rating + w18 - 3))\n",
      "∂S_short/∂w19 = -s_last**(1 - w19)*exp(w17*(rating + w18 - 3))*log(s_last)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, exp, log, diff\n",
    "\n",
    "s_last, rating = symbols(\"s_last rating\")\n",
    "w17, w18, w19 = symbols(\"w17 w18 w19\")\n",
    "\n",
    "s_new_short = s_last ** (1 - w19) * exp(w17 * (rating - 3 + w18))\n",
    "\n",
    "ds_short_dw17 = diff(s_new_short, w17).simplify()\n",
    "ds_short_dw18 = diff(s_new_short, w18).simplify()\n",
    "ds_short_dw19 = diff(s_new_short, w19).simplify()\n",
    "\n",
    "print(\"--- Gradients for stability_short_term ---\")\n",
    "print(f\"∂S_short/∂w17 = {ds_short_dw17}\")\n",
    "print(f\"∂S_short/∂w18 = {ds_short_dw18}\")\n",
    "print(f\"∂S_short/∂w19 = {ds_short_dw19}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradients for next_d ---\n",
      "∂D_new/∂w4 = w7\n",
      "∂D_new/∂w5 = -3*w7*exp(3*w5)\n",
      "∂D_new/∂w6 = -(d_last - 10)*(rating - 3)*(w7 - 1)/9\n",
      "∂D_new/∂w7 = -d_last + w4 - w6*(d_last - 10)*(rating - 3)/9 - exp(3*w5) + 1\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, exp, diff\n",
    "\n",
    "d_last, rating = symbols(\"d_last rating\")\n",
    "w4, w5, w6, w7 = symbols(\"w4 w5 w6 w7\")\n",
    "\n",
    "init_d_4 = w4 - exp(w5 * (4 - 1)) + 1\n",
    "delta_d = -w6 * (rating - 3)\n",
    "d_intermediate = d_last + delta_d * (10 - d_last) / 9\n",
    "d_new = w7 * init_d_4 + (1 - w7) * d_intermediate\n",
    "\n",
    "dd_dw4 = diff(d_new, w4).simplify()\n",
    "dd_dw5 = diff(d_new, w5).simplify()\n",
    "dd_dw6 = diff(d_new, w6).simplify()\n",
    "dd_dw7 = diff(d_new, w7).simplify()\n",
    "\n",
    "print(\"--- Gradients for next_d ---\")\n",
    "print(f\"∂D_new/∂w4 = {dd_dw4}\")\n",
    "print(f\"∂D_new/∂w5 = {dd_dw5}\")\n",
    "print(f\"∂D_new/∂w6 = {dd_dw6}\")\n",
    "print(f\"∂D_new/∂w7 = {dd_dw7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "S_MIN = 0.001\n",
    "\n",
    "\n",
    "class FSRS_one_step:\n",
    "    def __init__(self, w: List[float], lr: float = 1e-2):\n",
    "        self.w = w\n",
    "        self.lr = lr\n",
    "        self.s_min = S_MIN\n",
    "\n",
    "    def forgetting_curve(self, t: float, s: float) -> float:\n",
    "        decay = -self.w[20]\n",
    "        if decay == 0 or s == 0:\n",
    "            return 1.0\n",
    "        factor = math.pow(0.9, 1 / decay) - 1\n",
    "        return math.pow(1 + factor * t / s, decay)\n",
    "\n",
    "    def init_stability(self, rating: int) -> float:\n",
    "        return max(self.s_min, self.w[rating - 1])\n",
    "\n",
    "    def init_difficulty(self, rating: int) -> float:\n",
    "        val = self.w[4] - (math.exp(self.w[5] * (rating - 1)) - 1)\n",
    "        return max(1, min(10, val))\n",
    "\n",
    "    def next_difficulty(self, d: float, rating: int) -> float:\n",
    "        init_d_4 = self.w[4] - (math.exp(self.w[5] * 3) - 1)\n",
    "        delta_d = -self.w[6] * (rating - 3)\n",
    "        linear_damping = delta_d * (10 - d) / 9 if d < 10 else 0\n",
    "        d_intermediate = d + linear_damping\n",
    "        new_d = self.w[7] * init_d_4 + (1 - self.w[7]) * d_intermediate\n",
    "        return max(1, min(10, new_d))\n",
    "\n",
    "    def stability_short_term(self, s: float, rating: int) -> float:\n",
    "        if s <= 0:\n",
    "            return self.s_min\n",
    "        sinc = math.exp(self.w[17] * (rating - 3 + self.w[18])) * math.pow(\n",
    "            s, -self.w[19]\n",
    "        )\n",
    "        new_s = s * (max(1, sinc) if rating >= 3 else sinc)\n",
    "        return max(self.s_min, new_s)\n",
    "\n",
    "    def stability_after_success(\n",
    "        self, s: float, d: float, r: float, rating: int\n",
    "    ) -> float:\n",
    "        hard_penalty = self.w[15] if rating == 2 else 1.0\n",
    "        easy_bonus = self.w[16] if rating == 4 else 1.0\n",
    "        new_s = s * (\n",
    "            1\n",
    "            + math.exp(self.w[8])\n",
    "            * (11 - d)\n",
    "            * math.pow(s, -self.w[9])\n",
    "            * (math.exp((1 - r) * self.w[10]) - 1)\n",
    "            * hard_penalty\n",
    "            * easy_bonus\n",
    "        )\n",
    "        return max(self.s_min, new_s)\n",
    "\n",
    "    def stability_after_failure(self, s: float, d: float, r: float) -> float:\n",
    "        s_main = (\n",
    "            self.w[11]\n",
    "            * math.pow(d, -self.w[12])\n",
    "            * (math.pow(s + 1, self.w[13]) - 1)\n",
    "            * math.exp((1 - r) * self.w[14])\n",
    "        )\n",
    "        s_min_penalty = s / math.exp(self.w[17] * self.w[18])\n",
    "        return max(self.s_min, min(s_main, s_min_penalty))\n",
    "\n",
    "    def step(self, delta_t, rating, last_s, last_d):\n",
    "        if last_s is None:\n",
    "            return self.init_stability(rating), self.init_difficulty(rating)\n",
    "        elif delta_t == 0:\n",
    "            return self.stability_short_term(last_s, rating), self.next_difficulty(\n",
    "                last_d, rating\n",
    "            )\n",
    "        else:\n",
    "            r = self.forgetting_curve(delta_t, last_s)\n",
    "            if rating == 1:\n",
    "                return self.stability_after_failure(\n",
    "                    last_s, last_d, r\n",
    "                ), self.next_difficulty(last_d, rating)\n",
    "            else:\n",
    "                return self.stability_after_success(\n",
    "                    last_s, last_d, r, rating\n",
    "                ), self.next_difficulty(last_d, rating)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        last_s = None\n",
    "        last_d = None\n",
    "        outputs = []\n",
    "        for delta_t, rating in inputs:\n",
    "            last_s, last_d = self.step(delta_t, rating, last_s, last_d)\n",
    "            outputs.append((last_s, last_d))\n",
    "\n",
    "        self.last_s, self.last_d = outputs[-2] if len(outputs) > 1 else (None, None)\n",
    "        self.new_s, self.new_d = outputs[-1]\n",
    "        self.last_delta_t = inputs[-1][0]\n",
    "        self.last_rating = inputs[-1][1]\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, delta_t, y):\n",
    "        \"\"\"\n",
    "        Perform a single step of backpropagation.\n",
    "        :param delta_t: Time elapsed in days.\n",
    "        :param y: Actual outcome (0 for fail, 1 for success).\n",
    "        \"\"\"\n",
    "        p = -self.w[20]\n",
    "        factor = math.pow(0.9, 1 / p) - 1\n",
    "        new_r = self.forgetting_curve(delta_t, self.new_s)\n",
    "        dL_dR = (new_r - y) / (new_r * (new_r - 1))\n",
    "\n",
    "        # --- START: ADDED GRADIENT CALCULATION FOR w[20] ---\n",
    "        # This gradient depends on the state BEFORE the review (last_s, delta_t)\n",
    "        if new_r > 1e-6 and new_r < 1.0 - 1e-6:\n",
    "            # Using a more stable, manually derived formula for dL/dp\n",
    "            log_r = math.log(new_r)\n",
    "            log_0_9 = math.log(0.9)\n",
    "\n",
    "            # d(logR)/dp\n",
    "            d_log_r_dp = log_r / p - (delta_t * (factor + 1) * log_0_9) / (\n",
    "                p * (self.new_s + delta_t * factor)\n",
    "            )\n",
    "\n",
    "            # dL/dp = (dL/dR) * (dR/dp) = (R-y)/(R(1-R)) * (R * d(logR)/dp)\n",
    "            grad_p = dL_dR * new_r * d_log_r_dp\n",
    "\n",
    "            self.w[20] -= self.lr * grad_p\n",
    "        # --- END: ADDED GRADIENT CALCULATION FOR w[20] ---\n",
    "\n",
    "        dR_ds = (\n",
    "            new_r\n",
    "            * p\n",
    "            * factor\n",
    "            * delta_t\n",
    "            / (self.new_s * (factor * delta_t + self.new_s))\n",
    "        )\n",
    "        grad_s = dL_dR * dR_ds\n",
    "        if self.last_s is None:\n",
    "            if new_r > 1e-6 and new_r < 1.0 - 1e-6:\n",
    "                self.w[self.last_rating - 1] -= self.lr * grad_s\n",
    "        else:\n",
    "            if p == 0:\n",
    "                return\n",
    "\n",
    "            # --- Update weights based on the path taken ---\n",
    "            if delta_t < 1:  # Short-term path\n",
    "                if self.last_s > 0:\n",
    "                    g17 = self.last_s * (self.last_rating - 3 + self.w[18])\n",
    "                    g18 = self.last_s * self.w[17]\n",
    "                    g19 = -self.last_s * math.log(self.last_s)\n",
    "                    self.w[17] -= self.lr * grad_s * g17\n",
    "                    self.w[18] -= self.lr * grad_s * g18\n",
    "                    self.w[19] -= self.lr * grad_s * g19\n",
    "            else:  # Long-term path\n",
    "                last_r = self.forgetting_curve(self.last_delta_t, self.last_s)\n",
    "                ds_new_d_last_d = 0.0  # This will connect S to D gradients\n",
    "\n",
    "                if self.last_rating > 1:  # Success\n",
    "                    ds_new_d_last_d = (\n",
    "                        -(self.last_s ** (1 - self.w[9]))\n",
    "                        * (self.w[15] if self.last_rating == 2 else 1.0)\n",
    "                        * (self.w[16] if self.last_rating == 4 else 1.0)\n",
    "                        * math.exp(self.w[8])\n",
    "                        * (math.exp((1 - last_r) * self.w[10]) - 1)\n",
    "                    )\n",
    "                    g8 = ds_new_d_last_d * (11 - self.last_d)\n",
    "                    g9 = g8 * math.log(self.last_s) if self.last_s > 0 else 0\n",
    "                    g10 = (\n",
    "                        self.last_s\n",
    "                        * math.exp(self.w[8])\n",
    "                        * (11 - self.last_d)\n",
    "                        * math.pow(self.last_s, -self.w[9])\n",
    "                        * (1 - last_r)\n",
    "                        * math.exp((1 - last_r) * self.w[10])\n",
    "                        * (self.w[15] if self.last_rating == 2 else 1.0)\n",
    "                        * (self.w[16] if self.last_rating == 4 else 1.0)\n",
    "                    )\n",
    "                    self.w[8] -= self.lr * grad_s * g8\n",
    "                    self.w[9] -= self.lr * grad_s * g9\n",
    "                    self.w[10] -= self.lr * grad_s * g10\n",
    "                    if self.last_rating == 2 and self.w[15] > 0:\n",
    "                        self.w[15] -= (\n",
    "                            self.lr * grad_s * (self.new_s - self.last_s) / self.w[15]\n",
    "                        )\n",
    "                    if self.last_rating == 4 and self.w[16] > 0:\n",
    "                        self.w[16] -= (\n",
    "                            self.lr * grad_s * (self.new_s - self.last_s) / self.w[16]\n",
    "                        )\n",
    "                else:  # Failure\n",
    "                    s_main = (\n",
    "                        self.w[11]\n",
    "                        * math.pow(self.last_d, -self.w[12])\n",
    "                        * (math.pow(self.last_s + 1, self.w[13]) - 1)\n",
    "                        * math.exp((1 - last_r) * self.w[14])\n",
    "                    )\n",
    "                    s_min_penalty = self.last_s / math.exp(self.w[17] * self.w[18])\n",
    "\n",
    "                    if s_main < s_min_penalty:\n",
    "                        ds_new_d_last_d = (\n",
    "                            -s_main * self.w[12] / self.last_d if self.last_d > 0 else 0\n",
    "                        )\n",
    "                        g11 = s_main / self.w[11] if self.w[11] != 0 else 0\n",
    "                        g12 = -s_main * math.log(self.last_d) if self.last_d > 0 else 0\n",
    "                        g13 = (\n",
    "                            self.w[11]\n",
    "                            * math.pow(self.last_d, -self.w[12])\n",
    "                            * math.pow(self.last_s + 1, self.w[13])\n",
    "                            * math.log(self.last_s + 1)\n",
    "                            * math.exp((1 - last_r) * self.w[14])\n",
    "                            if self.last_s >= 0\n",
    "                            else 0\n",
    "                        )\n",
    "                        g14 = s_main * (1 - last_r)\n",
    "                        self.w[11] -= self.lr * grad_s * g11\n",
    "                        self.w[12] -= self.lr * grad_s * g12\n",
    "                        self.w[13] -= self.lr * grad_s * g13\n",
    "                        self.w[14] -= self.lr * grad_s * g14\n",
    "                    else:\n",
    "                        g17 = -s_min_penalty * self.w[18]\n",
    "                        g18 = -s_min_penalty * self.w[17]\n",
    "                        self.w[17] -= self.lr * grad_s * g17\n",
    "                        self.w[18] -= self.lr * grad_s * g18\n",
    "\n",
    "                # Update difficulty weights via chain rule\n",
    "                if ds_new_d_last_d != 0:\n",
    "                    grad_d_w4 = self.w[7]\n",
    "                    grad_d_w5 = -3 * self.w[7] * math.exp(3 * self.w[5])\n",
    "                    grad_d_w6 = (\n",
    "                        -(self.last_d - 10)\n",
    "                        * (self.last_rating - 3)\n",
    "                        * (self.w[7] - 1)\n",
    "                        / 9\n",
    "                    )\n",
    "                    init_d_4 = self.w[4] - (math.exp(self.w[5] * 3) - 1)\n",
    "                    delta_d_term = (\n",
    "                        -self.w[6] * (self.last_rating - 3) * (self.last_d - 10) / 9\n",
    "                    )\n",
    "                    grad_d_w7 = init_d_4 - (self.last_d + delta_d_term)\n",
    "\n",
    "                    self.w[4] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w4\n",
    "                    self.w[5] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w5\n",
    "                    self.w[6] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w6\n",
    "                    self.w[7] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w7\n",
    "\n",
    "        self.clamp_weights()\n",
    "\n",
    "    def clamp_weights(self):\n",
    "        # Clamping bounds based on provided instructions\n",
    "        self.w[0] = max(S_MIN, min(self.w[0], 100))\n",
    "        self.w[1] = max(S_MIN, min(self.w[1], 100))\n",
    "        self.w[2] = max(S_MIN, min(self.w[2], 100))\n",
    "        self.w[3] = max(S_MIN, min(self.w[3], 100))\n",
    "        self.w[4] = max(1, min(self.w[4], 10))\n",
    "        self.w[5] = max(0.001, min(self.w[5], 4))\n",
    "        self.w[6] = max(0.001, min(self.w[6], 4))\n",
    "        self.w[7] = max(0.001, min(self.w[7], 0.75))\n",
    "        self.w[8] = max(0, min(self.w[8], 4.5))\n",
    "        self.w[9] = max(0, min(self.w[9], 0.8))\n",
    "        self.w[10] = max(0.001, min(self.w[10], 3.5))\n",
    "        self.w[11] = max(0.001, min(self.w[11], 5))\n",
    "        self.w[12] = max(0.001, min(self.w[12], 0.25))\n",
    "        self.w[13] = max(0.001, min(self.w[13], 0.9))\n",
    "        self.w[14] = max(0, min(self.w[14], 4))\n",
    "        self.w[15] = max(0, min(self.w[15], 1))\n",
    "        self.w[16] = max(1, min(self.w[16], 6))\n",
    "        self.w[17] = max(0, min(self.w[17], 2))\n",
    "        self.w[18] = max(0, min(self.w[18], 2))\n",
    "        self.w[19] = max(0.01, min(self.w[19], 0.8))\n",
    "        self.w[20] = max(0.1, min(self.w[20], 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMETER = [\n",
    "    0.212,  # w[0] initial stability for again\n",
    "    1.2931,  # w[1] initial stability for hard\n",
    "    2.3065,  # w[2] initial stability for good\n",
    "    8.2956,  # w[3] initial stability for easy\n",
    "    6.4133,  # w[4] initial difficulty\n",
    "    0.8334,  # w[5] initial difficulty rating offset\n",
    "    3.0194,  # w[6] next difficulty rating offset\n",
    "    0.001,  # w[7] next difficulty reversion\n",
    "    1.8722,  # w[8] stability after success\n",
    "    0.1666,  # w[9] stability after success S decay\n",
    "    0.796,  # w[10] stability after success R bonus\n",
    "    1.4835,  # w[11] stability after failure\n",
    "    0.0614,  # w[12] stability after failure\n",
    "    0.2629,  # w[13] stability after failure\n",
    "    1.6483,  # w[14] stability after failure\n",
    "    0.6014,  # w[15] stability after success\n",
    "    1.8729,  # w[16] stability after success\n",
    "    0.5425,  # w[17] short term stability\n",
    "    0.0912,  # w[18] short term stability\n",
    "    0.0658,  # w[19] short term stability\n",
    "    0.1542,  # w[20] forgetting curve decay\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learner recalled the card, so the stability parameter should increase. The retrievability will decay slowly.\n",
    "\n",
    "The learner recalled the card before the 90% point, so the decay parameter should increase, too. The retrievability before the 90% point will decay slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3065\n",
      "[0.212, 1.2931, 2.3066994027269585, 8.2956, 6.4133, 0.8334, 3.0194, 0.001, 1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.15477478372347328]\n",
      "0.00019940272695828654\n",
      "0.0005747837234732767\n"
     ]
    }
   ],
   "source": [
    "fsrs = FSRS_one_step(DEFAULT_PARAMETER.copy())\n",
    "\n",
    "inputs = []\n",
    "\n",
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "inputs.append((0, last_rating))\n",
    "\n",
    "new_s = fsrs.init_stability(last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.init_difficulty(last_rating)\n",
    "\n",
    "delta_t = 1\n",
    "\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 1)\n",
    "print(fsrs.w)\n",
    "\n",
    "print(fsrs.w[2] - DEFAULT_PARAMETER[2])\n",
    "print(fsrs.w[20] - DEFAULT_PARAMETER[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learner recalled the card, so the stability parameter should increase. The retrievability will decay slowly.\n",
    "\n",
    "The learner recalled the card after the 90% point, so the decay parameter should decrease. The retrievability after the 90% point will decay slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3065\n",
      "[0.212, 1.2931, 2.3068746934098394, 8.2956, 6.4133, 0.8334, 3.0194, 0.001, 1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.1537154302886968]\n",
      "0.00037469340983919963\n",
      "-0.00048456971130320103\n"
     ]
    }
   ],
   "source": [
    "fsrs = FSRS_one_step(DEFAULT_PARAMETER.copy())\n",
    "\n",
    "inputs = []\n",
    "\n",
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "inputs.append((0, last_rating))\n",
    "\n",
    "new_s = fsrs.init_stability(last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.init_difficulty(last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 1)\n",
    "print(fsrs.w)\n",
    "\n",
    "print(fsrs.w[2] - DEFAULT_PARAMETER[2])\n",
    "print(fsrs.w[20] - DEFAULT_PARAMETER[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learner forgot the card, so the stability parameter should decrease. The retrievability will decay quickly.\n",
    "\n",
    "The learner forget the card before the 90% point, so the decay parameter should decrease, too. The retrievability before the 90% point will decay quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3065\n",
      "[0.212, 1.2931, 2.3029478816387297, 8.2956, 6.4133, 0.8334, 3.0194, 0.001, 1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.143960923288005]\n",
      "-0.003552118361270562\n",
      "-0.010239076711995004\n"
     ]
    }
   ],
   "source": [
    "fsrs = FSRS_one_step(DEFAULT_PARAMETER.copy())\n",
    "\n",
    "inputs = []\n",
    "\n",
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "inputs.append((0, last_rating))\n",
    "\n",
    "new_s = fsrs.init_stability(last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.init_difficulty(last_rating)\n",
    "\n",
    "delta_t = 1\n",
    "\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 0)\n",
    "print(fsrs.w)\n",
    "\n",
    "print(fsrs.w[2] - DEFAULT_PARAMETER[2])\n",
    "print(fsrs.w[20] - DEFAULT_PARAMETER[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learner forgot the card, so the stability parameter should decrease. The retrievability will decay quickly.\n",
    "\n",
    "The learner forget the card after the 90% point, so the decay parameter should increase, too. The retrievability after the 90% point will decay quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3065\n",
      "[0.212, 1.2931, 2.303727385757546, 8.2956, 6.4133, 0.8334, 3.0194, 0.001, 1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.1577856645666613]\n",
      "-0.002772614242454008\n",
      "0.0035856645666612896\n"
     ]
    }
   ],
   "source": [
    "fsrs = FSRS_one_step(DEFAULT_PARAMETER.copy())\n",
    "\n",
    "inputs = []\n",
    "\n",
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "inputs.append((0, last_rating))\n",
    "\n",
    "new_s = fsrs.init_stability(last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.init_difficulty(last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 0)\n",
    "print(fsrs.w)\n",
    "\n",
    "print(fsrs.w[2] - DEFAULT_PARAMETER[2])\n",
    "print(fsrs.w[20] - DEFAULT_PARAMETER[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.958313738080541\n",
      "[0.212, 1.2931, 2.303727385757546, 8.2956, 6.413299971043636, 0.8334010584938395, 3.0194, 0.0011995016600122384, 1.8719428125920823, 0.16638536980045215, 0.7963348792460392, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.15830317463973395]\n"
     ]
    }
   ],
   "source": [
    "last_s = new_s\n",
    "last_d = new_d\n",
    "last_t = 2\n",
    "r = fsrs.forgetting_curve(last_t, last_s)\n",
    "last_rating = 3\n",
    "inputs.append((last_t, last_rating))\n",
    "\n",
    "new_s = fsrs.stability_after_success(last_s, last_d, r, last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 1)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.358322448354761\n",
      "[0.212, 1.2931, 2.303727385757546, 8.2956, 6.413299933670745, 0.8334024246564425, 3.0193454357079843, 0.001248959311664799, 1.8719428125920823, 0.16638536980045215, 0.7963348792460392, 1.484221683979635, 0.06060066935390815, 0.2684440036518798, 1.6483267388708307, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.15628668652239472]\n"
     ]
    }
   ],
   "source": [
    "last_s = new_s\n",
    "last_d = new_d\n",
    "last_t = 2\n",
    "r = fsrs.forgetting_curve(last_t, last_s)\n",
    "last_rating = 1\n",
    "inputs.append((last_t, last_rating))\n",
    "\n",
    "new_s = fsrs.stability_after_failure(last_s, last_d, r)\n",
    "print(new_s)\n",
    "new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "fsrs.forward(inputs)\n",
    "fsrs.backward(delta_t, 1)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3001622760377325\n",
      "[0.212, 1.2931, 2.3001622760377325, 8.2956, 6.413300932597923, 0.8333659107173972, 3.0193454357079843, 0.0010000073250437235, 1.8811349346582065, 0.2204486571206611, 0.7847058197258312, 1.484221683979635, 0.06060066935390815, 0.2684440036518798, 1.6483267388708307, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.10006540653431892]\n"
     ]
    }
   ],
   "source": [
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "inputs = [(0, last_rating)]\n",
    "\n",
    "for y in [0 if i % 10 == 0 else 1 for i in range(700)]:\n",
    "    new_s = fsrs.init_stability(last_rating)\n",
    "    new_d = fsrs.init_difficulty(last_rating)\n",
    "    delta_t = 1\n",
    "    fsrs.forward(inputs)\n",
    "    fsrs.backward(delta_t, y)\n",
    "    inputs.append((delta_t, last_rating))\n",
    "\n",
    "\n",
    "print(new_s)\n",
    "print(fsrs.w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsrs4anki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
