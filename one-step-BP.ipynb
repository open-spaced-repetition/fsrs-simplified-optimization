{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_ds=p*t*(-y*(((s + t)/s)**p - 1) - y + 1)/(s*(s + t)*(((s + t)/s)**p - 1))\n",
      "dL_dp=(y*((s + t)/s)**p - 1)*log((s + t)/s)/(((s + t)/s)**p - 1)\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, log, diff, exp\n",
    "\n",
    "# Symbols\n",
    "y, s, t, p = symbols(\"y s t p\")\n",
    "\n",
    "# Retrievability (R)\n",
    "R = (1 + t / s) ** -p\n",
    "\n",
    "# Loss Function (L)\n",
    "L = -(y * log(R) + (1 - y) * log(1 - R))\n",
    "\n",
    "# Gradient of Loss w.r.t. Stability (s)\n",
    "dL_ds = diff(L, s).simplify()\n",
    "\n",
    "# Gradient of Loss w.r.t. power (p, which is w[20])\n",
    "dL_dp = diff(L, p).simplify()\n",
    "\n",
    "print(f\"{dL_ds=}\")\n",
    "print(f\"{dL_dp=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_w8=last_s**(1 - w9)*w15*w16*(1 - exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p))*(last_d - 11)*exp(w8)\n",
      "grad_w9=last_s**(1 - w9)*w15*w16*(last_d - 11)*(exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p) - 1)*exp(w8)*log(last_s)\n",
      "grad_w10=-last_s**(1 - w9)*w15*w16*(last_d - 11)*(((last_s + t)/last_s)**p - 1)*exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p + w8)/((last_s + t)/last_s)**p\n",
      "grad_last_d=last_s**(1 - w9)*w15*w16*(1 - exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p))*exp(w8)\n",
      "grad_w15=last_s**(1 - w9)*w16*(1 - exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p))*(last_d - 11)*exp(w8)\n",
      "grad_w16=last_s**(1 - w9)*w15*(1 - exp(w10*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p))*(last_d - 11)*exp(w8)\n"
     ]
    }
   ],
   "source": [
    "# Symbols for the success case\n",
    "last_s, last_d, t, p = symbols(\"last_s last_d t p\")\n",
    "w8, w9, w10, w15, w16 = symbols(\"w8 w9 w10 w15 w16\")\n",
    "\n",
    "# Retrievability (r)\n",
    "r = (1 + t / last_s) ** -p\n",
    "\n",
    "# new_s formula (using w15 and w16 as placeholders for hard_penalty and easy_bonus)\n",
    "new_s = last_s * (\n",
    "    1\n",
    "    + exp(w8)\n",
    "    * (11 - last_d)\n",
    "    * last_s ** (-w9)\n",
    "    * (exp((1 - r) * w10) - 1)\n",
    "    * w15 # hard_penalty\n",
    "    * w16 # easy_bonus\n",
    ")\n",
    "\n",
    "# Gradients w.r.t weights\n",
    "grad_w8 = diff(new_s, w8).simplify()\n",
    "grad_w9 = diff(new_s, w9).simplify()\n",
    "grad_w10 = diff(new_s, w10).simplify()\n",
    "\n",
    "# Gradient w.r.t last difficulty\n",
    "grad_last_d = diff(new_s, last_d).simplify()\n",
    "\n",
    "# Gradients for penalty/bonus are the term itself\n",
    "grad_w15 = diff(new_s, w15).simplify()\n",
    "grad_w16 = diff(new_s, w16).simplify()\n",
    "\n",
    "\n",
    "print(f\"{grad_w8=}\")\n",
    "print(f\"{grad_w9=}\")\n",
    "print(f\"{grad_w10=}\")\n",
    "print(f\"{grad_last_d=}\")\n",
    "print(f\"{grad_w15=}\")\n",
    "print(f\"{grad_w16=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_w11=((last_s + 1)**w13 - 1)*exp(w14 - w14/((last_s + t)/last_s)**p)/last_d**w12\n",
      "grad_w12=w11*(1 - (last_s + 1)**w13)*exp(w14 - w14/((last_s + t)/last_s)**p)*log(last_d)/last_d**w12\n",
      "grad_w13=w11*(last_s + 1)**w13*exp(w14 - w14/((last_s + t)/last_s)**p)*log(last_s + 1)/last_d**w12\n",
      "grad_w14=w11*(((last_s + t)/last_s)**p - 1)*((last_s + 1)**w13 - 1)*exp(w14*(((last_s + t)/last_s)**p - 1)/((last_s + t)/last_s)**p)/(last_d**w12*((last_s + t)/last_s)**p)\n",
      "grad_last_d_fail=last_d**(-w12 - 1)*w11*w12*(1 - (last_s + 1)**w13)*exp(w14 - w14/((last_s + t)/last_s)**p)\n",
      "grad_w17=-last_s*w18*exp(-w17*w18)\n",
      "grad_w18=-last_s*w17*exp(-w17*w18)\n"
     ]
    }
   ],
   "source": [
    "# Symbols for the failure case\n",
    "last_s, last_d, t, p = symbols(\"last_s last_d t p\")\n",
    "w11, w12, w13, w14, w17, w18 = symbols(\"w11 w12 w13 w14 w17 w18\")\n",
    "\n",
    "# Retrievability (r)\n",
    "r = (1 + t / last_s) ** -p\n",
    "\n",
    "# Main failure formula for new_s\n",
    "new_s_main = w11 * last_d**(-w12) * ((last_s + 1)**w13 - 1) * exp((1 - r) * w14)\n",
    "# Minimum stability formula\n",
    "new_s_min = last_s / exp(w17 * w18)\n",
    "\n",
    "# Gradients for the main formula\n",
    "grad_w11 = diff(new_s_main, w11).simplify()\n",
    "grad_w12 = diff(new_s_main, w12).simplify()\n",
    "grad_w13 = diff(new_s_main, w13).simplify()\n",
    "grad_w14 = diff(new_s_main, w14).simplify()\n",
    "grad_last_d_fail = diff(new_s_main, last_d).simplify()\n",
    "\n",
    "# Gradients for the minimum stability formula\n",
    "grad_w17 = diff(new_s_min, w17).simplify()\n",
    "grad_w18 = diff(new_s_min, w18).simplify()\n",
    "\n",
    "\n",
    "print(f\"{grad_w11=}\")\n",
    "print(f\"{grad_w12=}\")\n",
    "print(f\"{grad_w13=}\")\n",
    "print(f\"{grad_w14=}\")\n",
    "print(f\"{grad_last_d_fail=}\")\n",
    "print(f\"{grad_w17=}\")\n",
    "print(f\"{grad_w18=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_d_w4=w7\n",
      "grad_d_w5=-3*w7*exp(3*w5)\n",
      "grad_d_w6=-(last_d - 10)*(rating - 3)*(w7 - 1)/9\n",
      "grad_d_w7=-last_d + w4 - w6*(last_d - 10)*(rating - 3)/9 - exp(3*w5) + 1\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, diff, exp\n",
    "\n",
    "# Symbols for difficulty calculation\n",
    "last_d, rating = symbols(\"last_d rating\")\n",
    "w4, w5, w6, w7 = symbols(\"w4 w5 w6 w7\")\n",
    "\n",
    "# Formula for initial D when rating is 4 (for mean reversion)\n",
    "init_d_4 = w4 - exp(w5 * (4 - 1)) + 1\n",
    "\n",
    "# Intermediate new_d before mean reversion\n",
    "# Note: delta_d * (10 - old_d) / 9 is linear_damping from the pytorch code\n",
    "delta_d = -w6 * (rating - 3)\n",
    "d_intermediate = last_d + delta_d * (10 - last_d) / 9\n",
    "\n",
    "# Final new_d after mean reversion\n",
    "new_d = w7 * init_d_4 + (1 - w7) * d_intermediate\n",
    "\n",
    "# Gradients of new_d w.r.t relevant weights\n",
    "grad_d_w4 = diff(new_d, w4).simplify()\n",
    "grad_d_w5 = diff(new_d, w5).simplify()\n",
    "grad_d_w6 = diff(new_d, w6).simplify()\n",
    "grad_d_w7 = diff(new_d, w7).simplify()\n",
    "\n",
    "print(f\"{grad_d_w4=}\")\n",
    "print(f\"{grad_d_w5=}\")\n",
    "print(f\"{grad_d_w6=}\")\n",
    "print(f\"{grad_d_w7=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import math\n",
    "\n",
    "S_MIN = 0.001\n",
    "\n",
    "class FSRS_one_step:\n",
    "    def __init__(self, w: List[float], lr: float = 1e-2):\n",
    "        self.w = w\n",
    "        self.lr = lr\n",
    "\n",
    "    def power_forgetting_curve(self, t, s):\n",
    "        return (1 + t / s) ** (-self.w[20])\n",
    "\n",
    "    def init_stability(self, rating: int) -> float:\n",
    "        return max(S_MIN, self.w[rating - 1])\n",
    "\n",
    "    def init_difficulty(self, rating: int) -> float:\n",
    "        return max(1, min(10, self.w[4] - math.exp(self.w[5] * (rating - 1)) + 1))\n",
    "    \n",
    "    def next_difficulty(self, d: float, rating: int) -> float:\n",
    "        # From PyTorch code:\n",
    "        init_d_4 = self.w[4] - math.exp(self.w[5] * (4 - 1)) + 1\n",
    "        delta_d = -self.w[6] * (rating - 3)\n",
    "        linear_damping = delta_d * (10 - d) / 9\n",
    "        d_intermediate = d + linear_damping\n",
    "        # Mean reversion\n",
    "        new_d = self.w[7] * init_d_4 + (1 - self.w[7]) * d_intermediate\n",
    "        return max(1, min(10, new_d))\n",
    "\n",
    "    def stability_after_success(self, s: float, d: float, r: float, rating: int) -> float:\n",
    "        hard_penalty = self.w[15] if rating == 2 else 1.0\n",
    "        easy_bonus = self.w[16] if rating == 4 else 1.0\n",
    "        new_s = s * (\n",
    "            1\n",
    "            + math.exp(self.w[8])\n",
    "            * (11 - d)\n",
    "            * math.pow(s, -self.w[9])\n",
    "            * (math.exp((1 - r) * self.w[10]) - 1)\n",
    "            * hard_penalty\n",
    "            * easy_bonus\n",
    "        )\n",
    "        return max(S_MIN, new_s)\n",
    "\n",
    "    def stability_after_failure(self, s: float, d: float, r: float) -> float:\n",
    "        s_main = (\n",
    "            self.w[11]\n",
    "            * math.pow(d, -self.w[12])\n",
    "            * (math.pow(s + 1, self.w[13]) - 1)\n",
    "            * math.exp((1 - r) * self.w[14])\n",
    "        )\n",
    "        s_min_penalty = s / math.exp(self.w[17] * self.w[18])\n",
    "        return max(S_MIN, min(s_main, s_min_penalty))\n",
    "\n",
    "    def update_weights(self, last_s: Optional[float], last_d: Optional[float], delta_t: int, rating: int, y: int):\n",
    "        \"\"\"\n",
    "        Perform a single step of backpropagation.\n",
    "        :param last_s: Stability before the review.\n",
    "        :param last_d: Difficulty before the review.\n",
    "        :param delta_t: Time elapsed in days.\n",
    "        :param rating: User feedback (1:Fail, 2:Hard, 3:Good, 4:Easy).\n",
    "        :param y: Actual outcome (0 for fail, 1 for success).\n",
    "        \"\"\"\n",
    "        # Initial review case\n",
    "        if last_s is None:\n",
    "            s0 = self.init_stability(rating)\n",
    "            d0 = self.init_difficulty(rating)\n",
    "            r = self.power_forgetting_curve(delta_t, s0)\n",
    "            \n",
    "            # Simplified gradient for initial stabilities\n",
    "            grad_s = self.w[20] * delta_t * (y * (1 - ((delta_t + s0) / s0)**self.w[20]) + y - 1) / (s0 * (delta_t + s0) * (((delta_t + s0) / s0)**self.w[20] - 1))\n",
    "            self.w[rating - 1] -= self.lr * grad_s * 5 # Amplify learning for first reviews\n",
    "            \n",
    "            # No update for difficulty on first review as it's directly calculated\n",
    "            return\n",
    "\n",
    "        # Subsequent review\n",
    "        r = self.power_forgetting_curve(delta_t, last_s)\n",
    "        \n",
    "        # dL/ds_new\n",
    "        cur_s = (\n",
    "            self.stability_after_success(last_s, last_d, r, rating)\n",
    "            if rating > 1\n",
    "            else self.stability_after_failure(last_s, last_d, r)\n",
    "        )\n",
    "        \n",
    "        r_new = self.power_forgetting_curve(delta_t, cur_s)\n",
    "        \n",
    "        # Using a simplified, more stable gradient for dL/ds\n",
    "        # Based on dL/dR * dR/ds\n",
    "        # dL/dR = (R - y) / (R * (1 - R))\n",
    "        # dR/ds = (p * t * R) / (s * (s + t))\n",
    "        if r_new < 0.999 and r_new > 0.001:\n",
    "            grad_s = (r_new - y) / (r_new * (1 - r_new)) * (self.w[20] * delta_t * r_new) / (cur_s * (cur_s + delta_t))\n",
    "        else:\n",
    "            grad_s = (r_new - y) * self.w[20] * delta_t / (cur_s * (cur_s + delta_t))\n",
    "\n",
    "        # dL/dp (w20)\n",
    "        grad_p = (y * ((last_s + delta_t)/last_s)**self.w[20] - 1) * math.log((last_s + delta_t)/last_s) / (((last_s + delta_t)/last_s)**self.w[20] - 1)\n",
    "        self.w[20] -= self.lr * grad_s * grad_p * 0.1 # Smaller learning rate for p\n",
    "\n",
    "        # Gradients for difficulty parameters (chain rule)\n",
    "        # d(last_d)/dw_i\n",
    "        grad_d_w4 = self.w[7]\n",
    "        grad_d_w5 = -3 * self.w[7] * math.exp(3 * self.w[5])\n",
    "        grad_d_w6 = -(last_d - 10) * (rating - 3) * (self.w[7] - 1) / 9\n",
    "        init_d_4 = self.w[4] - math.exp(self.w[5] * 3) + 1\n",
    "        delta_d_term = -self.w[6] * (rating - 3) * (last_d - 10) / 9\n",
    "        grad_d_w7 = init_d_4 - (last_d + delta_d_term)\n",
    "\n",
    "        if rating > 1: # Success\n",
    "            # Common term: ds_new/d(last_d)\n",
    "            ds_new_d_last_d = last_s**(1-self.w[9]) * (self.w[15] if rating==2 else 1) * \\\n",
    "                             (self.w[16] if rating==4 else 1) * \\\n",
    "                             (1 - math.exp(self.w[10]*(1-r))) * math.exp(self.w[8])\n",
    "\n",
    "            # Gradients of S w.r.t. w_i\n",
    "            g8 = last_s**(1-self.w[9]) * (self.w[15] if rating==2 else 1) * \\\n",
    "                 (self.w[16] if rating==4 else 1) * (1 - math.exp(self.w[10]*(1-r))) * \\\n",
    "                 (last_d-11) * math.exp(self.w[8])\n",
    "            g9 = last_s**(1-self.w[9]) * (self.w[15] if rating==2 else 1) * \\\n",
    "                 (self.w[16] if rating==4 else 1) * (last_d-11) * \\\n",
    "                 (math.exp(self.w[10]*(1-r)) - 1) * math.exp(self.w[8]) * math.log(last_s)\n",
    "            g10 = -last_s**(1-self.w[9]) * (self.w[15] if rating==2 else 1) * \\\n",
    "                  (self.w[16] if rating==4 else 1) * (last_d-11) * (1-r) * \\\n",
    "                  math.exp(self.w[10]*(1-r) + self.w[8])\n",
    "            \n",
    "            self.w[8] -= self.lr * grad_s * g8\n",
    "            self.w[9] -= self.lr * grad_s * g9\n",
    "            self.w[10] -= self.lr * grad_s * g10\n",
    "\n",
    "            if rating == 2:\n",
    "                g15 = last_s**(1-self.w[9]) * (self.w[16] if rating==4 else 1) * \\\n",
    "                      (1-math.exp(self.w[10]*(1-r))) * (last_d-11) * math.exp(self.w[8])\n",
    "                self.w[15] -= self.lr * grad_s * g15\n",
    "            if rating == 4:\n",
    "                g16 = last_s**(1-self.w[9]) * (self.w[15] if rating==2 else 1) * \\\n",
    "                      (1-math.exp(self.w[10]*(1-r))) * (last_d-11) * math.exp(self.w[8])\n",
    "                self.w[16] -= self.lr * grad_s * g16\n",
    "\n",
    "        else: # Failure\n",
    "            s_main = self.w[11] * math.pow(last_d, -self.w[12]) * \\\n",
    "                     (math.pow(last_s + 1, self.w[13]) - 1) * math.exp((1 - r) * self.w[14])\n",
    "            s_min_penalty = last_s / math.exp(self.w[17] * self.w[18])\n",
    "            \n",
    "            if s_main < s_min_penalty:\n",
    "                # Gradients for main failure formula\n",
    "                ds_new_d_last_d = last_d**(-self.w[12]-1) * self.w[11] * self.w[12] * \\\n",
    "                                  (1-(last_s+1)**self.w[13]) * math.exp((1-r)*self.w[14])\n",
    "\n",
    "                g11 = ((last_s+1)**self.w[13] - 1) * math.exp((1-r)*self.w[14]) / last_d**self.w[12]\n",
    "                g12 = self.w[11]*(1-(last_s+1)**self.w[13]) * math.exp((1-r)*self.w[14]) * \\\n",
    "                      math.log(last_d) / last_d**self.w[12]\n",
    "                g13 = self.w[11]*(last_s+1)**self.w[13] * math.exp((1-r)*self.w[14]) * \\\n",
    "                      math.log(last_s+1) / last_d**self.w[12]\n",
    "                g14 = self.w[11]*((last_s+1)**self.w[13]-1)*(1-r) * \\\n",
    "                      math.exp((1-r)*self.w[14]) / last_d**self.w[12]\n",
    "                \n",
    "                self.w[11] -= self.lr * grad_s * g11\n",
    "                self.w[12] -= self.lr * grad_s * g12\n",
    "                self.w[13] -= self.lr * grad_s * g13\n",
    "                self.w[14] -= self.lr * grad_s * g14\n",
    "            else:\n",
    "                # Gradients for min stability penalty\n",
    "                ds_new_d_last_d = 0 # No dependency on difficulty\n",
    "                g17 = -last_s * self.w[18] * math.exp(-self.w[17] * self.w[18])\n",
    "                g18 = -last_s * self.w[17] * math.exp(-self.w[17] * self.w[18])\n",
    "                self.w[17] -= self.lr * grad_s * g17\n",
    "                self.w[18] -= self.lr * grad_s * g18\n",
    "\n",
    "        # Update difficulty weights via chain rule: dL/dw = dL/dS * dS/dD * dD/dw\n",
    "        if ds_new_d_last_d != 0:\n",
    "            self.w[4] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w4\n",
    "            self.w[5] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w5\n",
    "            self.w[6] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w6\n",
    "            self.w[7] -= self.lr * grad_s * ds_new_d_last_d * grad_d_w7\n",
    "\n",
    "        self.clamp_weights()\n",
    "\n",
    "    def clamp_weights(self):\n",
    "        # Clamping bounds based on provided instructions\n",
    "        self.w[0] = max(S_MIN, min(self.w[0], 100))\n",
    "        self.w[1] = max(S_MIN, min(self.w[1], 100))\n",
    "        self.w[2] = max(S_MIN, min(self.w[2], 100))\n",
    "        self.w[3] = max(S_MIN, min(self.w[3], 100))\n",
    "        self.w[4] = max(1, min(self.w[4], 10))\n",
    "        self.w[5] = max(0.001, min(self.w[5], 4))\n",
    "        self.w[6] = max(0.001, min(self.w[6], 4))\n",
    "        self.w[7] = max(0.001, min(self.w[7], 0.75))\n",
    "        self.w[8] = max(0, min(self.w[8], 4.5))\n",
    "        self.w[9] = max(0, min(self.w[9], 0.8))\n",
    "        self.w[10] = max(0.001, min(self.w[10], 3.5))\n",
    "        self.w[11] = max(0.001, min(self.w[11], 5))\n",
    "        self.w[12] = max(0.001, min(self.w[12], 0.25))\n",
    "        self.w[13] = max(0.001, min(self.w[13], 0.9))\n",
    "        self.w[14] = max(0, min(self.w[14], 4))\n",
    "        self.w[15] = max(0, min(self.w[15], 1))\n",
    "        self.w[16] = max(1, min(self.w[16], 6))\n",
    "        self.w[17] = max(0, min(self.w[17], 2))\n",
    "        self.w[18] = max(0, min(self.w[18], 2))\n",
    "        self.w[19] = max(0.01, min(self.w[19], 0.8))\n",
    "        self.w[20] = max(0.1, min(self.w[20], 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMETER = [\n",
    "    0.212,  # w[0] initial stability for again\n",
    "    1.2931,  # w[1] initial stability for hard\n",
    "    2.3065,  # w[2] initial stability for good\n",
    "    8.2956,  # w[3] initial stability for easy\n",
    "    6.4133,  # w[4] initial difficulty\n",
    "    0.8334,  # w[5] initial difficulty rating offset\n",
    "    3.0194,  # w[6] next difficulty rating offset\n",
    "    0.001,  # w[7] next difficulty reversion\n",
    "    1.8722,  # w[8] stability after success\n",
    "    0.1666,  # w[9] stability after success S decay\n",
    "    0.796,  # w[10] stability after success R bonus\n",
    "    1.4835,  # w[11] stability after failure\n",
    "    0.0614,  # w[12] stability after failure\n",
    "    0.2629,  # w[13] stability after failure\n",
    "    1.6483,  # w[14] stability after failure\n",
    "    0.6014,  # w[15] stability after success\n",
    "    1.8729,  # w[16] stability after success\n",
    "    0.5425,  # w[17] short term stability\n",
    "    0.0912,  # w[18] short term stability\n",
    "    0.0658,  # w[19] short term stability\n",
    "    0.1542,  # w[20] forgetting curve decay\n",
    "]\n",
    "fsrs = FSRS_one_step(DEFAULT_PARAMETER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3065\n",
      "[0.212, 1.2931, 2.3075109563210816, 8.2956, 6.4133, 0.8334, 3.0194, 0.001, 1.8722, 0.1666, 0.796, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.1542]\n"
     ]
    }
   ],
   "source": [
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "\n",
    "new_s = fsrs.init_stability(last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.init_difficulty(last_rating)\n",
    "\n",
    "delta_t = 1\n",
    "\n",
    "fsrs.update_weights(last_s, last_d, delta_t, last_rating, 1)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.09180365110379\n",
      "[0.212, 1.2931, 2.3075109563210816, 8.2956, 6.413299974388176, 0.8334009362348808, 3.0194, 0.001176458667875016, 1.8724274815527482, 0.16640988656348088, 0.7962997137236069, 1.4835, 0.0614, 0.2629, 1.6483, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.1542016235475612]\n"
     ]
    }
   ],
   "source": [
    "last_s = new_s\n",
    "last_d = new_d\n",
    "last_t = 2\n",
    "r = fsrs.power_forgetting_curve(last_t, last_s)\n",
    "last_rating = 3\n",
    "\n",
    "new_s = fsrs.stability_after_success(last_s, last_d, r, last_rating)\n",
    "print(new_s)\n",
    "new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "fsrs.update_weights(last_s, last_d, delta_t, last_rating, 1)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36740013700412\n",
      "[0.212, 1.2931, 2.3075109563210816, 8.2956, 6.413299938353644, 0.8334022534734087, 3.0193463674272074, 0.0012251500068517023, 1.8724274815527482, 0.16640988656348088, 0.7962997137236069, 1.484209935014972, 0.060612990868730676, 0.26836092728593314, 1.6483381684385614, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.15421973009588114]\n"
     ]
    }
   ],
   "source": [
    "last_s = new_s\n",
    "last_d = new_d\n",
    "last_t = 2\n",
    "r = fsrs.power_forgetting_curve(last_t, last_s)\n",
    "last_rating = 1\n",
    "\n",
    "new_s = fsrs.stability_after_failure(last_s, last_d, r)\n",
    "print(new_s)\n",
    "new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "delta_t = 3\n",
    "\n",
    "fsrs.update_weights(last_s, last_d, delta_t, last_rating, 1)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.701100094648134\n",
      "[0.212, 1.2931, 3.701543274098277, 8.2956, 6.413299938353644, 0.8334022534734087, 3.0193463674272074, 0.0012251500068517023, 1.8724274815527482, 0.16640988656348088, 0.7962997137236069, 1.484209935014972, 0.060612990868730676, 0.26836092728593314, 1.6483381684385614, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.15421973009588114]\n"
     ]
    }
   ],
   "source": [
    "last_s = None\n",
    "last_d = None\n",
    "last_rating = 3\n",
    "\n",
    "for y in [0 if i % 10 == 0 else 1 for i in range(700)]:\n",
    "    new_s = fsrs.init_stability(last_rating)\n",
    "    new_d = fsrs.init_difficulty(last_rating)\n",
    "    delta_t = 1\n",
    "    fsrs.update_weights(last_s, last_d, delta_t, last_rating, y)\n",
    "\n",
    "print(new_s)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.342864079476962\n",
      "[0.212, 1.2931, 3.701543274098277, 8.2956, 6.4136497486461606, 0.82084281609334, 3.0193463674272074, 0.009681091822580885, 1.7885961898479326, 0.22451731005137343, 0.6753931757123799, 1.484209935014972, 0.060612990868730676, 0.26836092728593314, 1.6483381684385614, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.17414558907713734]\n"
     ]
    }
   ],
   "source": [
    "last_s = 2\n",
    "last_d = 5\n",
    "last_t = 2\n",
    "r = fsrs.power_forgetting_curve(last_t, last_s)\n",
    "last_rating = 3\n",
    "for y in [0 if i % 10 == 0 else 1 for i in range(600)]:\n",
    "    new_s = fsrs.stability_after_success(last_s, last_d, r, last_rating)\n",
    "    new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "    delta_t = 10\n",
    "\n",
    "    fsrs.update_weights(last_s, last_d, delta_t, last_rating, y)\n",
    "print(new_s)\n",
    "print(fsrs.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7886169429977454\n",
      "[0.212, 1.2931, 3.701543274098277, 8.2956, 6.413645735056117, 0.8209840243848162, 3.018806098946315, 0.012603483722860518, 1.7885961898479326, 0.22451731005137343, 0.6753931757123799, 1.4833571896314541, 0.06381863076347875, 0.3441622866905756, 1.6483368526083544, 0.6014, 1.8729, 0.5425, 0.0912, 0.0658, 0.231276937759554]\n"
     ]
    }
   ],
   "source": [
    "last_s = 50\n",
    "last_d = 5\n",
    "last_t = 2\n",
    "r = fsrs.power_forgetting_curve(last_t, last_s)\n",
    "last_rating = 1\n",
    "for y in [0 if i % 10 == 0 else 1 for i in range(500)]:\n",
    "    new_s = fsrs.stability_after_failure(last_s, last_d, r)\n",
    "    new_d = fsrs.next_difficulty(last_d, last_rating)\n",
    "\n",
    "    delta_t = 2\n",
    "\n",
    "    fsrs.update_weights(last_s, last_d, delta_t, last_rating, y)\n",
    "print(new_s)\n",
    "print(fsrs.w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsrs4anki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
